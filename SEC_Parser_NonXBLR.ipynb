{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import regex as re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Scrape a Singular 10-K File and Extract Income Tax Paid Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_income_tax_paid(url):\n",
    "\n",
    "    # request file from url\n",
    "    r = requests.get(url, headers = {'User-agent': 'goyalavantika'})\n",
    "\n",
    "    # create beautifulsoup object and normalize text\n",
    "    html = bs(r.content, \"html.parser\")\n",
    "    text = html.get_text(' ', strip=True)\n",
    "    text = unicodedata.normalize(\"NFKD\", text).encode('ascii', 'ignore').decode('utf8')\n",
    "    text = text.split(\"\\n\")\n",
    "    text = \" \".join(text)\n",
    "    text = text.replace('  ',' ').replace('\\n',' ').replace(' $ ', ' ').replace('$','')\n",
    "\n",
    "    # search for Supplementary Data/Information in entire file\n",
    "    supp_info_regex = r'(?:.){50}Supplementa(?:l|ry)\\s(?:Information|Data|Disclosures)(?:.){5000}'\n",
    "    supp_info_pattern = re.compile(supp_info_regex, flags=re.I)\n",
    "    supp_info_list = supp_info_pattern.findall(text)\n",
    "\n",
    "    # search for Consolidated Cash Flow in entire file\n",
    "    cons_cf_regex = r'(?:.){50}(?:Consolidated|Additional)\\sCash\\sFlow(?:.){2000}'\n",
    "    cons_cf_pattern = re.compile(cons_cf_regex, flags=re.I)\n",
    "    cons_cf_list = cons_cf_pattern.findall(text)\n",
    "\n",
    "    # search for Cash Paid in entire file\n",
    "    cash_paid_regex = r'(?:.){50}(?:Tax|Cash)\\s(?:Paid|Payments?)\\s(?:for|of)?(?:\\sIncome)?(?:\\sTax)?(?:.){1000}'\n",
    "    cash_paid_pattern = re.compile(cash_paid_regex, flags=re.I)\n",
    "    cash_paid_list = cash_paid_pattern.findall(text)\n",
    "\n",
    "    # search for Income Tax Paid in entire file\n",
    "    tax_paid_regex = r'(?:.){50}(?:NET\\s)?INCOME\\sTAX(?:ES)?\\s(?:PAID)?(?:.){150}'\n",
    "    tax_paid_pattern = re.compile(tax_paid_regex, flags=re.I)\n",
    "    tax_paid_list = tax_paid_pattern.findall(text)\n",
    "\n",
    "    # if Supplementary Data/Info section, search for Consolidated Cash Flow within each\n",
    "    if supp_info_list:\n",
    "        for supp_info in supp_info_list:\n",
    "            cons_cf_list2 = cons_cf_pattern.findall(supp_info)\n",
    "            cons_cf_list = cons_cf_list2 + cons_cf_list\n",
    "    \n",
    "    # if Supplementary Data/Info section, search for Cash Paid within each\n",
    "            cash_paid_list2 = cash_paid_pattern.findall(supp_info)\n",
    "            cash_paid_list = cash_paid_list2 + cash_paid_list\n",
    "    \n",
    "    # if Supplementary Data/Info section, search for Income Tax Paid within each\n",
    "            # more general regex pattern when searching within a section\n",
    "            tax_paid_regex2 = r'(?:.){0,50}(?:income|paid|payments?|tax(?:es)?)\\s(?:\\D+\\s){0,3}(?:income|paid|payments?|tax(?:es)?)\\s(?:.){100}'\n",
    "            tax_paid_pattern2 = re.compile(tax_paid_regex2, flags=re.I)\n",
    "            tax_paid_list2 = tax_paid_pattern2.findall(supp_info)\n",
    "            tax_paid_list = tax_paid_list2 + tax_paid_list\n",
    "    \n",
    "    # if Consolidated Cash Flow section, search for Cash Paid within each\n",
    "    if cons_cf_list:\n",
    "        for cons_cf in cons_cf_list:\n",
    "            cash_paid_list2 = cash_paid_pattern.findall(cons_cf)\n",
    "            cash_paid_list = cash_paid_list2 + cash_paid_list\n",
    "\n",
    "    # if Consolidated Cash Flow section, search for Income Tax Paid within each\n",
    "            # more general regex pattern when searching within a section\n",
    "            tax_paid_regex2 = r'(?:.){0,50}(?:income|paid|payments?|tax(?:es)?)\\s(?:\\D+\\s){0,3}(?:income|paid|payments?|tax(?:es)?)(?:.){100}'\n",
    "            tax_paid_pattern2 = re.compile(tax_paid_regex2, flags=re.I)\n",
    "            tax_paid_list2 = tax_paid_pattern2.findall(cons_cf)\n",
    "            tax_paid_list = tax_paid_list2 + tax_paid_list\n",
    "\n",
    "    # if Cash Paid section, search for Income Tax Paid within each\n",
    "    if cash_paid_list:\n",
    "        for cash_paid in cash_paid_list:\n",
    "            # more general regex pattern when searching within a section\n",
    "            tax_paid_regex2 = r'(?:.){0,50}(?:income|paid|payments?|tax(?:es)?)\\s(?:\\D+\\s){0,3}(?:income|paid|payments?|tax(?:es)?)(?:.){125}'\n",
    "            tax_paid_pattern2 = re.compile(tax_paid_regex2, flags=re.I)\n",
    "            tax_paid_list2 = tax_paid_pattern2.findall(cash_paid)\n",
    "            tax_paid_list = tax_paid_list2 + tax_paid_list\n",
    "    \n",
    "    # remove any match that contains Provision, Benefit, or Loss\n",
    "    drop_list = []\n",
    "    for item in tax_paid_list:\n",
    "        if item.lower().find('provision') != -1:\n",
    "            drop_list.append(item)\n",
    "        elif item.lower().find('loss') != -1:\n",
    "            drop_list.append(item)\n",
    "        elif item.lower().find('refunded') != -1:\n",
    "            drop_list.append(item)\n",
    "        elif item.lower().find('reserves') != -1:\n",
    "            drop_list.append(item)\n",
    "    \n",
    "    # if income tax paid sections found then extract value\n",
    "    if tax_paid_list:\n",
    "        # drop the first 50 characters from each match and remove duplicates from list\n",
    "        tax_paid_list = list(dict.fromkeys([x[50:] for x in tax_paid_list if x not in drop_list]))\n",
    "\n",
    "        # find the first numerical value\n",
    "        numerical_regex = r'\\s(?:\\((?:\\s)?)?\\d{1,3}(?:,\\d{3})?(?:,\\d{3})?(?:\\.\\d{1,3})?(?:\\s?million)?(?:\\s?\\))?\\D'\n",
    "        numerical_pattern = re.compile(numerical_regex, flags=re.I)\n",
    "        for item in tax_paid_list:\n",
    "            value = numerical_pattern.findall(item)\n",
    "            if value:\n",
    "                return value[0]\n",
    "    \n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Run the Scraping Function on Multiple 10-K Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_income_tax_paid_multiple(url_list):\n",
    "    results = []\n",
    "    for url in (url_list):\n",
    "        results.append(find_income_tax_paid(url))\n",
    "    return pd.DataFrame({'Income Taxes Paid':results})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input List of 10-K URLs for Parsing Here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITP = find_income_tax_paid_multiple(urls_list_name_here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Resulting Dataframe to Given Filepath As CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITP.to_csv('file_path_here', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
